{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Senior Design Team 1725, Classifying AIS, MM Solution Training\n",
        "This file is a jupyter notebook containing\n",
        "the training results for the \"multiple models\"\n",
        "solution for the AIS Classification project.\n",
        "\n",
        "Intent: showcase a training method that can work\n",
        "        with any dataset size for a specific class\n",
        "        while also being flexible for training new models\n",
        "        that can handle other invasive species.\n",
        "\n",
        "Basically, rather than having one model that handles all species,\n",
        "we attempt to have multiple models chained together to handle identification"
      ],
      "metadata": {
        "id": "Mn9I90Y1rGRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Mounting:\n",
        "First, we want to access our dataset. To do this, we mount our sharepoint/OneDrive to colab. Can be done by following [this](https://medium.com/@pratikmukherjee32/mount-onedrive-to-google-colab-f941a3a96a79) guide.\n",
        "\n",
        "You must first insall rclone *locally*, then you can get it on Colab. The reason for this is because we need an API key for the mount to work properly."
      ],
      "metadata": {
        "id": "xUTncdzzrhMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.rclone.org/v1.69.0/rclone-v1.69.0-linux-amd64.deb\n",
        "!apt install ./rclone-v1.69.0-linux-amd64.deb"
      ],
      "metadata": {
        "id": "tNyKnfG3HOyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f5d568-94ce-4773-9b16-47a8a8915649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-06 00:37:28--  https://downloads.rclone.org/v1.69.0/rclone-v1.69.0-linux-amd64.deb\n",
            "Resolving downloads.rclone.org (downloads.rclone.org)... 95.217.6.16, 2a01:4f9:c012:7154::1\n",
            "Connecting to downloads.rclone.org (downloads.rclone.org)|95.217.6.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23665802 (23M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘rclone-v1.69.0-linux-amd64.deb’\n",
            "\n",
            "rclone-v1.69.0-linu 100%[===================>]  22.57M  9.28MB/s    in 2.4s    \n",
            "\n",
            "2025-02-06 00:37:31 (9.28 MB/s) - ‘rclone-v1.69.0-linux-amd64.deb’ saved [23665802/23665802]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'rclone' instead of './rclone-v1.69.0-linux-amd64.deb'\n",
            "The following NEW packages will be installed:\n",
            "  rclone\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 0 B/23.7 MB of archives.\n",
            "After this operation, 71.0 MB of additional disk space will be used.\n",
            "Get:1 /content/rclone-v1.69.0-linux-amd64.deb rclone amd64 1.69.0 [23.7 MB]\n",
            "Selecting previously unselected package rclone.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../rclone-v1.69.0-linux-amd64.deb ...\n",
            "Unpacking rclone (1.69.0) ...\n",
            "Setting up rclone (1.69.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to pass some arguments for this to work,\n",
        "# so make sure we still have the api key\n",
        "# (Note: you need to copy the ENTIRE struct, as the values are read as an array)\n",
        "\n",
        "# Also, make sure to clear the output! We don't want to have\n",
        "# loose api keys floating around the internet!\n",
        "!rclone config"
      ],
      "metadata": {
        "id": "Q09StzydMGfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo mkdir /content/onedrive\n",
        "# Create onedrive directory in colab"
      ],
      "metadata": {
        "id": "YgQYMyR0MJsJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1671dc3-caca-40a3-9f71-8ec35a3b14c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/onedrive’: File exists\n",
            "2025/02/06 01:01:55 CRITICAL: Fatal error: failed to mount FUSE fs: fusermount: exec: \"fusermount3\": executable file not found in $PATH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install fusermount3 to ensure proper mounting\n",
        "!sudo apt-get -y install fuse3"
      ],
      "metadata": {
        "id": "d14Tx6fQzYRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup rclone --vfs-cache-mode full mount onedrive: /content/onedrive &\n",
        "# After these commands, we should have a onedrive folder in the files section\n",
        "# within colab with everything we need!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-S7k7i7x2w7",
        "outputId": "2a01f02a-31f8-4dda-ffe5-bf62ab8c6df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Setup:\n",
        "What we want to do next is copy the files from the datasets we want to use for creating our first few models.\n",
        "\n",
        "Basically, we are copying the files to the colab environment because we don't want to overwrite what's going on with OneDrive and because we want a \"fresh\" place to store our training results\n",
        "\n",
        "##Word of warning:\n",
        "Doing this will consume disk resources on Colab, make sure you have enough space with the images you copy over!"
      ],
      "metadata": {
        "id": "zGHvT2bKLEEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import utilities to take random image sampling and copy to target directory\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Create a new directory specifically to hold dataset\n",
        "!sudo mkdir /content/SenDsgnTraining"
      ],
      "metadata": {
        "id": "2xY-r6jGNju_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code assistance from Joey George\n",
        "# Dataset path:\n",
        "source_dir = r\"/content/onedrive/Training Images/Training\"\n",
        "target_dir = r\"/content/SenDsgnTraining\"\n",
        "\n",
        "# Define classes for the smaller datasets\n",
        "# The options we have are:\n",
        "# \"narrowleaf_cattail\", \"none\", \"phragmites\", \"purple_loosestrife\"\n",
        "classes = [\"none\", \"purple_loosestrife\"]\n",
        "splits = {\"train\": 70, \"val\": 15, \"test\": 15}  # Percentage split"
      ],
      "metadata": {
        "id": "ncSguFh66VXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target directory structure\n",
        "for split in splits:\n",
        "    for class_name in classes:\n",
        "        os.makedirs(os.path.join(target_dir, split, class_name), exist_ok=True)"
      ],
      "metadata": {
        "id": "8kovwvOJ6kNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each class\n",
        "for class_name in classes:\n",
        "    source_path = os.path.join(source_dir, class_name)\n",
        "    images = [f for f in os.listdir(source_path) if f.endswith(\".jpg\")]\n",
        "\n",
        "    # Randomly sample 100 images\n",
        "    selected_images = random.sample(images, min(100, len(images)))\n",
        "\n",
        "    # Distribute images across train, val, test\n",
        "    split_counts = {k: int(v * len(selected_images) / 100) for k, v in splits.items()}\n",
        "    start_idx = 0\n",
        "    for split, count in split_counts.items():\n",
        "        split_path = os.path.join(target_dir, split, class_name)\n",
        "        for i in range(count):\n",
        "            img_name = f\"{start_idx}_{class_name}.jpg\"\n",
        "            shutil.copy(os.path.join(source_path, selected_images[start_idx]), os.path.join(split_path, img_name))\n",
        "            start_idx += 1"
      ],
      "metadata": {
        "id": "wkGvwNXh4eNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Now that we've gotten our dataset mounted and our splits taken care of, we can begin training.\n",
        "\n",
        "The best thing about the classification model is that no .yaml file is necessary, as the folder structure is enough to ensure the training, validation, and testing splits are recognized for each class!"
      ],
      "metadata": {
        "id": "upsYpZdeL4cF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KoPmRlbHxBP",
        "outputId": "26cf76ec-da28-430a-d946-056d01f983b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.71 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 37.8/235.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Install Ultralytics and dependencies\n",
        "%pip install ultralytics  # install\n",
        "from ultralytics import YOLO, checks\n",
        "checks()  # checks\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO(\"yolo11m-cls.pt\")  # Load a pretrained model\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=target_dir, epochs=10, imgsz=640)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ontZFaDx8atu",
        "outputId": "51fc387f-4e49-408e-a6d5-93fd99b2fc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m-cls.pt to 'yolo11m-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22.4M/22.4M [00:00<00:00, 74.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.71 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11m-cls.pt, data=/content/SenDsgnTraining, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/SenDsgnTraining/train... found 140 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/SenDsgnTraining/val... found 30 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/SenDsgnTraining/test... found 30 images in 2 classes ✅ \n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 10                  -1  1    660482  ultralytics.nn.modules.head.Classify         [512, 2]                      \n",
            "YOLO11m-cls summary: 187 layers, 10,355,778 parameters, 10,355,778 gradients, 39.6 GFLOPs\n",
            "Transferred 294/296 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 109MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/SenDsgnTraining/train... 140 images, 0 corrupt: 100%|██████████| 140/140 [00:00<00:00, 267.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/SenDsgnTraining/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/SenDsgnTraining/val... 30 images, 0 corrupt: 100%|██████████| 30/30 [00:00<00:00, 245.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/SenDsgnTraining/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 49 weight(decay=0.0), 50 weight(decay=0.0005), 50 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      6.11G     0.7019         16        640:  22%|██▏       | 2/9 [00:18<00:53,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 755k/755k [00:00<00:00, 15.7MB/s]\n",
            "       1/10      6.11G     0.5226         12        640: 100%|██████████| 9/9 [01:59<00:00, 13.29s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.933          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      6.14G     0.1049         12        640: 100%|██████████| 9/9 [01:43<00:00, 11.45s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      6.18G     0.0348         12        640: 100%|██████████| 9/9 [03:20<00:00, 22.27s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      6.15G    0.02601         12        640: 100%|██████████| 9/9 [03:01<00:00, 20.22s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      6.17G    0.01053         12        640: 100%|██████████| 9/9 [03:51<00:00, 25.76s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      6.15G    0.03329         12        640: 100%|██████████| 9/9 [03:46<00:00, 25.14s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      6.15G   0.007548         12        640: 100%|██████████| 9/9 [04:05<00:00, 27.29s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      6.15G    0.01002         12        640: 100%|██████████| 9/9 [03:47<00:00, 25.28s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      6.15G   0.009017         12        640: 100%|██████████| 9/9 [04:25<00:00, 29.45s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      6.15G    0.00592         12        640: 100%|██████████| 9/9 [03:55<00:00, 26.18s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.583 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 20.9MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 20.9MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.71 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11m-cls summary (fused): 138 layers, 10,344,194 parameters, 0 gradients, 39.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/SenDsgnTraining/train... found 140 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/SenDsgnTraining/val... found 30 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/SenDsgnTraining/test... found 30 images in 2 classes ✅ \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.8ms preprocess, 6.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just in case, we want to download the \"runs\" folder and save our training results\n",
        "!zip -r /content/run1.zip /content/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtyUP93jG5CE",
        "outputId": "4ee11912-03a3-4c5d-ae4d-98b4118a39f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/runs/ (stored 0%)\n",
            "  adding: content/runs/classify/ (stored 0%)\n",
            "  adding: content/runs/classify/train/ (stored 0%)\n",
            "  adding: content/runs/classify/train/results.csv (deflated 63%)\n",
            "  adding: content/runs/classify/train/train_batch2.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/train_batch0.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/results.png (deflated 12%)\n",
            "  adding: content/runs/classify/train/confusion_matrix.png (deflated 36%)\n",
            "  adding: content/runs/classify/train/val_batch0_pred.jpg (deflated 0%)\n",
            "  adding: content/runs/classify/train/val_batch0_labels.jpg (deflated 0%)\n",
            "  adding: content/runs/classify/train/train_batch1.jpg (deflated 1%)\n",
            "  adding: content/runs/classify/train/confusion_matrix_normalized.png (deflated 34%)\n",
            "  adding: content/runs/classify/train/weights/ (stored 0%)\n",
            "  adding: content/runs/classify/train/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/classify/train/weights/best.pt (deflated 8%)\n",
            "  adding: content/runs/classify/train/args.yaml (deflated 52%)\n",
            "  adding: content/runs/classify/train/events.out.tfevents.1738806706.69d83999022f.962.0 (deflated 94%)\n"
          ]
        }
      ]
    }
  ]
}